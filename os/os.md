[toc]

# 网络系统

### 零拷贝

- 传统 I/O ：CPU 指令 -> 磁盘控制器 -> 中断 -> CPU 拷贝数据到内存（期间不能执行其他操作）

- DMA 方式：DMA 控制器负责拷贝数据并发中断信号给 CPU

- 利用 `read/write` 的文件传输方式：4 次上下文切换、4 次数据拷贝

  ```
     read         read        write          write
  文件 -> 内核缓冲区 -> 用户缓冲区 -> socket 缓冲区 -> 网卡
       1            2           3             4
  ```

- 零拷贝

  - `mmap + write` ：利用 `mmap` 直接把内核缓冲区的数据映射到用户空间，减少了第 1 次拷贝

    4 次上下文切换、3 次数据拷贝

  - `sendfile` ：直接把内核缓冲区的数据拷贝到 socket 缓冲区，减少了第 2 次数据拷贝

    2 次上下文切换、3 次数据拷贝

  - `sendfile` + SG-DMA 技术：利用 `ethtool -k eth0 | grep scatter-gather` 命令查看网卡是否

    支持 scatter-gather 特性，将描述符和数据长度传到 socket 缓冲区后网卡的 SG-DMA 控制器直接将

    内核缓存中的数据拷贝到网卡的缓冲区，减少了第 2、3 次数据拷贝

    2 次上下文切换、2 次数据拷贝

- 大文件的传输：零拷贝技术是缓冲 I/O 使用了内核缓冲区（PageCache）。如果传输的是大文件，PageCache 会被

  大文件长期占据，所以针对大文件要使用 <font color=red>**异步 I/O + 直接 I/O**</font> 来绕过内核缓冲区。

### I/O 多路复用

- 基本模型

  ```
  socket()      socket()
                bind()
                listen()
  connect() --> accept() --> 服务器内核维护半连接队列和全连接队列
  write()   --> read()
  read()    --> write()
  ```

- 多进程模型：在 `accept` 函数返回后通过 `fork` 创建子进程，子进程会复制父进程的文件描述符，可以直接

  和客户端通信。

- 多线程模型：在 `accept` 函数返回后通过 `pthread_create` 创建线程，将已连接 socket 的文件描述符传递给

  线程函数在线程里和客户端进行通信。优化：全局的已连接 socket 队列 + 线程池。

- I/O 多路复用 —— <font color=red>**只使用一个进程来维护多个 socket **</font>

  - `select/poll` ：每次调用将已连接的 socket 放到文件描述符集合并<font color=red>**拷贝**</font>到内核，内核通过<font color=red>**遍历**</font>的方式

    将 socket 标记为可读或可写，然后再把整个集合<font color=red>**拷贝**</font>回用户态，用户态再通过<font color=red>**遍历**</font>找到可读或可写

    的 socket 并处理。
    
    区别：`select` 使用固定长度的 BitsMap 表示文件描述符集合，最大只能支持 `FD_SETSIZE(1024)` 个
    
    文件描述符；而 `poll` 使用链表来组织集合，去掉了最大个数限制。
    
  - `epoll` ：`epoll_create` 创建 -> `epoll_ctl` 添加/删除 -> `epoll_wait` 等待
  
    `epoll` 在内核里维护红黑树保存所有待检测的文件描述符，减少了内核和用户空间大量的数据拷贝。
  
    `epoll` 还维护了一个处于 I/O 就绪状态的文件描述符链表，调用 `epoll_wait` 会返回有事件发生的
  
    文件描述符的个数。
  
- 水平触发和边缘触发 —— 两种文件描述符准备就绪的通知模式

  水平触发：当被监控的 socket 上有可读事件发生时，服务器端不断地从 `epoll_wait ` 中苏醒，直到内核缓冲区

  数据被 `read` 函数读完才结束。**水平触发模式允许我们在任意时刻重复检查 I/O 状态，所以没有必要在每次就绪后**

  **尽可能多地执行 I/O **。

  边缘触发：如果文件描述符自上次状态检查以来有了新的 I/O 活动（比如新的输入）则触发通知，在

  另一个 I/O 事件到来前我们不会收到任何新的通知。**所以在收到通知后应该尽可能地读写数据。边缘触发模式**

  **一般和非阻塞 I/O 搭配使用**。

  `epoll` 支持边缘触发和水平触发（默认）的方式，而 `select/poll` 只支持水平触发，一般而言，边缘触发的

  方式会比水平触发的效率高。

### Reactor 和 Proactor 模式

- 演进：阻塞 I/O -> 非阻塞 I/O -> I/O 多路复用 -> 封装 -> **Reactor/Dispatcher 模式 —— 非阻塞同步网络模式**

- Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成。其中 Reactor 负责监听和分发

  连接事件和读写事件，处理资源池则负责处理事件。

  - 单 Reactor 单线程/进程：包括 Reactor（使用 `select` 监听并分发）、Acceptor 和 Handler 。

    **无法利用多核、处理业务时无法处理连接事件**。Redis 6.0 之前采用的方案。

  - 单 Reactor 多线程/进程：上一种模式的 Handler 不再负责处理，而只负责数据发送和接收。

    子线程的 Processor 负责具体的业务处理。**在利用多核性能的同时带来了资源竞争问题**。

    **上边两种模式在面对瞬时高并发时 Reactor 会成为性能瓶颈**。

  - 多 Reactor 多线程/进程：包括 MainReactor 和 SubReactor 。主线程只负责接收新连接，子线程负责完成
  
    后续的业务处理，**主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理**
  
    **结果发送给客户端**。Netty 和 Memcached 采用了此方案。
  
- Proactor 是一种异步网络模式。非阻塞 I/O 在内核数据未准备好时会立即返回，但是在数据准备好后将数据

  从内核态拷贝到用户态的过程仍然是同步完成的。在真正的异步 I/O 中，**内核数据准备好和数据从内核态拷贝**

  **到用户态这两个过程都不用等待**。并且拷贝是由内核完成的。

  所以：

  Reactor 模式感知的**待完成的就绪可读写事件** -> 来了事件操作系统通知应用进程，让应用进程来处理。

  Proactor 模式感知的是**已完成的读写事件** -> 来了事件操作系统来处理，处理完再通知应用进程。

